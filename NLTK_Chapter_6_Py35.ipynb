{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# 1.3   Document Classification\n",
    "#\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "\n",
    "# print(documents) --- DONT \n",
    "print(len(documents))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chamberlain', 'deconstruct', 'undiscernable', 'keeslar', 'reclusion', 'gotta', 'neptune', 'prophecy', 'gordo', 'noteriaty', 'responsibly', 'clamor', 'bordertown', 'nutter', 'draft', 'lieutenant', 'lifts', 'oscillation', 'finklestein', 'immuno']\n"
     ]
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words()) # All Words - Freq Dist created Converted to Lowercase \n",
    "word_features = list(all_words)[:20]  ### Original -- Get a list of the 2000 most frequent words -- OWN 20 \n",
    "print(word_features)                                                  ### OK dont \n",
    "\n",
    "\n",
    "'''\n",
    "The reason that we compute the set of all words in a document in ###[3], rather than just checking\n",
    "if word in document, is that checking whether a word occurs in a set is much faster than checking \n",
    "whether it occurs in a list\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def document_features(document): \n",
    "    document_words = set(document) ### [3]\n",
    "    features = {}\n",
    "    for word in word_features:                                         ### List created above \n",
    "        features['contains({})'.format(word)] = (word in document_words) ### Check if Word in INPUT_DOCUMENT == to Word in LIST word_features\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "\n",
      "['capsule', ':', 'the', 'best', 'place', 'to', 'start', ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See what the Review File is like ? \n",
    "#\n",
    "test1 = movie_reviews.words(\"pos/cv957_8737.txt\")\n",
    "print(type(test1))   ### http://www.nltk.org/_modules/nltk/corpus/reader/util.html\n",
    "                     ### <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
    "print(\"\")\n",
    "print(movie_reviews.words(\"pos/cv957_8737.txt\"))\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(deconstruct)': False, 'contains(oscillation)': False, 'contains(keeslar)': False, 'contains(reclusion)': False, 'contains(immuno)': False, 'contains(lifts)': False, 'contains(responsibly)': False, 'contains(gordo)': False, 'contains(bordertown)': False, 'contains(gotta)': False, 'contains(nutter)': False, 'contains(neptune)': False, 'contains(finklestein)': False, 'contains(undiscernable)': False, 'contains(draft)': False, 'contains(lieutenant)': False, 'contains(clamor)': False, 'contains(prophecy)': False, 'contains(chamberlain)': False, 'contains(noteriaty)': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(document_features(movie_reviews.words('pos/cv957_8737.txt'))) # OK dont Print \n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Needs to be Understood --------- \n",
    "## The LIST ---\"documents\" was RANDOM Shuffled \n",
    "\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]  ### \"documents\" is LIST from 1st Code Cell Above \n",
    "train_set, test_set = featuresets[100:], featuresets[:100] \n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) ### Thus we wont have the same Document as above == 'pos/cv957_8737.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47\n",
      "\n",
      "Most Informative Features\n",
      "    contains(lieutenant) = True              pos : neg    =      2.8 : 1.0\n",
      "       contains(neptune) = True              pos : neg    =      2.3 : 1.0\n",
      "         contains(draft) = True              neg : pos    =      1.8 : 1.0\n",
      "         contains(lifts) = True              neg : pos    =      1.7 : 1.0\n",
      "         contains(gotta) = True              pos : neg    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set)) ### [1]\n",
    "\n",
    "print(\"\")\n",
    "classifier.show_most_informative_features(5)\n",
    "\n",
    "# A review that Mentions -- neptune --- is 2.3 Times more likely to be POSITIVE than NEGATIVE !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.4   Part-of-Speech Tagging\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "suffix_fdist = nltk.FreqDist()\n",
    "for word in brown.words():       ## Original in brown.words()\n",
    "# movie_reviews.words\n",
    "#for word in movie_reviews.words(): ## Own in movie_reviews.words()\n",
    "     word = word.lower()\n",
    "     suffix_fdist[word[-1:]] += 1\n",
    "     suffix_fdist[word[-2:]] += 1\n",
    "     suffix_fdist[word[-3:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
     ]
    }
   ],
   "source": [
    "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
    "print(common_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', ',', 's', '.', 't', 'a', 'n', 'd', 'he', \"'\", 'y', 'the', 'r', 'is', 'of', 'to', 'o', '\"', 'g', 'in', '-', 'ng', 'nd', 'ing', 'f', 'er', 'l', 'and', ')', 'on', 'it', '(', 'h', 'as', 'es', 'at', 'ed', 're', 'i', 'm', 'ly', 'an', 'or', 'en', 'hat', 'his', 'st', 'ut', 'le', 'll', 'th', 'ne', 've', 'ts', 'k', 'me', 'al', 'be', 'ce', 'by', 'se', 'rs', 'nt', 'her', '?', 'ion', 'ith', 'w', 'ry', 'ch', 'ter', 'p', 'for', 'ot', 'lm', 'ilm', 'so', 'one', ':', 'but', 'ld', 'ie', 'ere', 'out', 'are', 'lly', 'ey', 'ke', 'ns', 'ers', 'ent', 'ay', 'nce', 'te', 'up', 'c', 'us', 'om', 'ow', 'et']\n"
     ]
    }
   ],
   "source": [
    "common_suffixes1 = [suffix for (suffix, count) in suffix_fdist1.most_common(100)]\n",
    "print(common_suffixes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_features(word):\n",
    "     features = {}\n",
    "     for suffix in common_suffixes:\n",
    "         features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
    "\n",
    "#print(len(featuresets))  ### Dont Print --- 100554"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.classify(pos_features('cats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.5   Exploiting Context\n",
    "\n",
    "\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "def pos_features(sentence, i): ###[1]\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:],   ### Original Ends here with --- \"suffix(3)\"\n",
    "               \"suffix(4)\": sentence[i][-4:], \n",
    "               \"suffix(5)\": sentence[i][-5:],\n",
    "               \"suffix(6)\": sentence[i][-6:]} ## No COMMA for the Last --- sentence[i]\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "__________________________________________________\n",
      " \n",
      "['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']\n",
      "__________________________________________________\n",
      " \n",
      "['The', 'September-October', 'term', 'jury', 'had', 'been', 'charged', 'by', 'Fulton', 'Superior', 'Court', 'Judge', 'Durwood', 'Pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'Mayor-nominate', 'Ivan', 'Allen', 'Jr.', '.']\n",
      "__________________________________________________\n",
      " \n",
      "['``', 'Only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.']\n",
      "__________________________________________________\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(brown.sents()[0]) # Own Code --- not done in book ? \n",
    "print(\"_\"*50)\n",
    "print(\" \")\n",
    "\n",
    "print(brown.sents()[1]) \n",
    "print(\"_\"*50)\n",
    "print(\" \")\n",
    "\n",
    "print(brown.sents()[2]) \n",
    "print(\"_\"*50)\n",
    "print(\" \")\n",
    "\n",
    "print(brown.sents()[3])   ### Three Instances of \"of\" \n",
    "print(\"_\"*50)\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': 'of',\n",
       " 'suffix(1)': 'h',\n",
       " 'suffix(2)': 'ch',\n",
       " 'suffix(3)': 'uch',\n",
       " 'suffix(4)': 'such',\n",
       " 'suffix(5)': 'such',\n",
       " 'suffix(6)': 'such'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[3], 6)\n",
    "\n",
    "# Actually no point as - all three instances of \"of\" shall have diff index values [i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': \"Atlanta's\",\n",
       " 'suffix(1)': 't',\n",
       " 'suffix(2)': 'nt',\n",
       " 'suffix(3)': 'ent'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': 'evidence',\n",
       " 'suffix(1)': \"'\",\n",
       " 'suffix(2)': \"''\",\n",
       " 'suffix(3)': \"''\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev-word': 'Jury',\n",
       " 'suffix(1)': 'd',\n",
       " 'suffix(2)': 'id',\n",
       " 'suffix(3)': 'aid',\n",
       " 'suffix(4)': 'said',\n",
       " 'suffix(5)': 'said',\n",
       " 'suffix(6)': 'said'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_features(brown.sents()[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
